---
title: "Stock Price Prediction"
author: "134780 Trevor Okinda"
date: "April 2024"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |     |
|----------------------------------------------|-----|
| **Student ID Number**                        | 134780 |
| **Student Name**                             | Trevor Okinda |
| **BBIT 4.2 Group**                           | C |
| **Project Name**                             | Stock Price Prediction Model |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```

```{r Load dataset}
# Load dataset
stock_data <- read.csv("stock.csv", colClasses = c(
  Date = "Date",
  High = "numeric",
  Low = "numeric",
  Open = "numeric",
  Close = "numeric",
  Volume = "numeric",
  Adj_Close = "numeric"
))

# Display the structure of the dataset
str(stock_data)

# View the first few rows of the dataset
head(stock_data)

# Open the dataset in a viewer window
View(stock_data)
```

```{r Measures of Frequency}
# Summary statistics for numeric variables
summary(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")])
```

```{r Measures of Central Tendency}
# Mean for numeric variables
mean_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], mean)
cat("Mean values:\n")
print(mean_values)

# Median for numeric variables
median_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], median)
cat("\nMedian values:\n")
print(median_values)
```

```{r Measures of Distrbution}
# Range for numeric variables
range_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], function(x) c(min(x), max(x)))
cat("Range values:\n")
print(range_values)

# Interquartile range (IQR) for numeric variables
iqr_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], IQR)
cat("\nInterquartile range (IQR) values:\n")
print(iqr_values)

# Standard deviation for numeric variables
sd_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], sd)
cat("\nStandard deviation values:\n")
print(sd_values)

# Variance for numeric variables
variance_values <- sapply(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")], var)
cat("\nVariance values:\n")
print(variance_values)
```

```{r Measures of Relationship}
# Correlation matrix for numeric variables
correlation_matrix <- cor(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")])
cat("Correlation matrix:\n")
print(correlation_matrix)

# Pairwise scatterplots for numeric variables
pairs(stock_data[, c("High", "Low", "Open", "Close", "Volume", "Adj_Close")])
```

```{r Basic Visualizations}
# Load necessary library
library(ggplot2)

# Univariate histogram for 'Close' price
ggplot(stock_data, aes(x = Close)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  labs(title = "Histogram of Close Price", x = "Close Price", y = "Frequency")

# Univariate boxplot for 'Volume'
ggplot(stock_data, aes(y = Volume)) +
  geom_boxplot(fill = "lightgreen", color = "black") +
  labs(title = "Boxplot of Volume", y = "Volume")

# Univariate density plot for 'High' price
ggplot(stock_data, aes(x = High)) +
  geom_density(fill = "orange", color = "black") +
  labs(title = "Density Plot of High Price", x = "High Price", y = "Density")

# Load necessary library
library(ggplot2)

# Multivariate scatter plot matrix
scatterplot_matrix <- ggplot(stock_data, aes(x = High, y = Low)) +
  geom_point(color = "blue") +
  labs(title = "Scatter Plot Matrix of High vs. Low Prices")

# Display the scatter plot matrix
print(scatterplot_matrix)

# Scatter plot with size encoding for 'Volume' and color encoding for 'High' prices
scatterplot <- ggplot(stock_data, aes(x = High, y = Low, size = Volume, color = High)) +
  geom_point(alpha = 0.7) +
  scale_size_continuous(name = "Volume") +
  scale_color_gradient(low = "green", high = "red", name = "High Price") +
  labs(title = "Scatter Plot of High vs. Low Prices with Volume Encoding")

# Display the scatter plot
print(scatterplot)

# Scatter plot with color encoding for 'Open' and 'Close' prices
scatterplot <- ggplot(stock_data, aes(x = Open, y = Close, color = abs(Close - Open))) +
  geom_point() +
  scale_color_gradient(low = "blue", high = "red", name = "Price Difference") +
  labs(title = "Scatter Plot of Open vs. Close Prices")

# Display the scatter plot
print(scatterplot)

```

```{r Missing Values}
# Check for missing values in the dataset
missing_values <- colSums(is.na(stock_data))

# Display the number of missing values for each variable
print(missing_values)

# Check if any missing values exist in the dataset
if (sum(missing_values) > 0) {
  print("Missing values are present in the dataset.")
} else {
  print("No missing values found in the dataset.")
}
```

```{r Standardization & Scaling}
# Standardization of numeric variables (mean = 0, standard deviation = 1)
numeric_vars <- c("High", "Low", "Open", "Close", "Volume", "Adj_Close")
stock_data_standardized <- scale(stock_data[, numeric_vars])

# Check the summary statistics of standardized variables
summary(stock_data_standardized)

# Min-max scaling of 'Volume' variable to range [0, 1]
min_volume <- min(stock_data$Volume)
max_volume <- max(stock_data$Volume)
stock_data$Volume_scaled <- (stock_data$Volume - min_volume) / (max_volume - min_volume)

# Check the summary statistics of scaled 'Volume' variable
summary(stock_data$Volume_scaled)
```

```{r Data Splitting}
# Set seed for reproducibility
set.seed(123)

# Determine the number of rows for training and testing sets
total_rows <- nrow(stock_data)
train_rows <- round(0.8 * total_rows)  # 80% for training
test_rows <- total_rows - train_rows   # Remaining 20% for testing

# Randomly shuffle the indices of rows
indices <- sample(total_rows)

# Split the indices into training and testing indices
train_indices <- indices[1:train_rows]
test_indices <- indices[(train_rows + 1):total_rows]

# Split the dataset into training and testing sets
train_data <- stock_data[train_indices, ]
test_data <- stock_data[test_indices, ]

# Check the dimensions of training and testing sets
cat("Training data dimensions:", dim(train_data), "\n")
cat("Testing data dimensions:", dim(test_data))
```

```{r ARIMA model training}
# Load necessary libraries
library(forecast)

# Fit an ARIMA model
model <- auto.arima(train_data)

# Make predictions on the test data
forecast_values <- forecast(model, h = length(test_data))

# Evaluate the model
accuracy(forecast_values, test_data)
```

```{r Save Model}
# Saving the ARIMA model
saveRDS(model, "./models/saved_arima_model.rds")

new_data <- data.frame(
  Date = as.Date("2024-04-24"),  # Example value for Date
  High = 2094.120117,  # Example value for High
  Low = 2070.290039,  # Example value for Low
  Open = 2084.419922,  # Example value for Open
  Close = 2089.139893,  # Example value for Close
  Volume = 3884930000,  # Example value for Volume
  Adj_Close = 2089.139893  # Example value for Adj Close
)

# Use the loaded model to make predictions
loaded_model <- readRDS("./models/saved_arima_model.rds")
predictions_loaded_model <- forecast(loaded_model, h = 1)

# Print predictions
print(predictions_loaded_model)
```


